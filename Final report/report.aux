\relax 
\providecommand*{\memsetcounter}[2]{}
\providecommand \babel@aux [2]{\global \let \babel@toc \@gobbletwo }
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Callaway2023rationaluse}
\babel@aux{danish}{}
\citation{Callaway2023rationaluse}
\citation{griffiths2015rational}
\citation{payne1993adaptive}
\citation{Callaway2023rationaluse}
\citation{sutton2018reinforcement}
\@writefile{toc}{\contentsline {paragraph}{Belief States and Frontier.}{3}{section*.8}\protected@file@percent }
\newlabel{eq:frontier_rewrite}{{1}{4}{Belief States and Frontier}{equation.0.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Metalevel Transition Function.}{4}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Metalevel Reward Function.}{4}{section*.10}\protected@file@percent }
\newlabel{eq:metalevel_reward_rewrite}{{2}{4}{Metalevel Reward Function}{equation.0.2}{}}
\newlabel{eq:Vsp_rewrite}{{3}{4}{Metalevel Reward Function}{equation.0.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Heuristic Models.}{5}{section*.12}\protected@file@percent }
\newlabel{eq:pStopH}{{4}{5}{Heuristic Models}{equation.0.4}{}}
\newlabel{eq:pSelectH}{{6}{5}{Heuristic Models}{equation.0.6}{}}
\@writefile{toc}{\contentsline {paragraph}{Random Model.}{5}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Optimal and Myopic Models.}{5}{section*.14}\protected@file@percent }
\newlabel{eq:pStopO}{{7}{5}{Optimal and Myopic Models}{equation.0.7}{}}
\newlabel{eq:pSelectO}{{8}{6}{Optimal and Myopic Models}{equation.0.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of the constant-variance environment used in our extension of Experiment 2. Each node conceals a reward (green or red), sampled from a common distribution (e.g.\ $\pm 25, \pm 9, \pm 1$). This figure is a schematic; actual experiments randomize the location of each reward at the start of each trial.}}{7}{figure.caption.16}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:constant_env}{{1}{7}{Illustration of the constant-variance environment used in our extension of Experiment 2. Each node conceals a reward (green or red), sampled from a common distribution (e.g.\ $\pm 25, \pm 9, \pm 1$). This figure is a schematic; actual experiments randomize the location of each reward at the start of each trial}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Why Reinforcement Learning?}{8}{section*.18}\protected@file@percent }
\newlabel{sec:cogcontrol}{{}{9}{Cognitive Control Modeling}{section*.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Post-hoc pairwise comparisons of mean planning scores}}{10}{figure.caption.25}\protected@file@percent }
\newlabel{fig:table_of_hoc}{{2}{10}{Post-hoc pairwise comparisons of mean planning scores}{figure.caption.25}{}}
\@writefile{toc}{\contentsline {paragraph}{Post-hoc pairwise comparisons.}{10}{section*.26}\protected@file@percent }
\newlabel{sec:gml}{{}{11}{Model Fit Using Geometric Mean Likelihood (GML)}{section*.27}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Geometric Mean Likelihood (GML) for Different Models. Higher GML suggests a better fit to human data.}}{11}{table.caption.28}\protected@file@percent }
\newlabel{tab:gml}{{1}{11}{Geometric Mean Likelihood (GML) for Different Models. Higher GML suggests a better fit to human data}{table.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces GML values across models. \textsc  {Optimal} obtains the highest geometric mean likelihood, indicating it better captures participants' observed decisions compared to the other strategies.}}{12}{figure.caption.29}\protected@file@percent }
\newlabel{fig:gml_plot}{{3}{12}{GML values across models. \textsc {Optimal} obtains the highest geometric mean likelihood, indicating it better captures participants' observed decisions compared to the other strategies}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Comparison of Strategies and Human Performance. Each curve shows expected reward as a function of how many nodes the agent expands (clicks). Black dots indicate human participants’ aggregated data.}}{13}{figure.caption.31}\protected@file@percent }
\newlabel{fig:reward_vs_clicks}{{4}{13}{Comparison of Strategies and Human Performance. Each curve shows expected reward as a function of how many nodes the agent expands (clicks). Black dots indicate human participants’ aggregated data}{figure.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Proportion of second-click expansions on the same path as a function of the first revealed node's value. Human data (black) reveals a strong “best-first” tendency for high positive values, closely resembling the \textsc  {Optimal} and \textsc  {Best} curves.}}{13}{figure.caption.32}\protected@file@percent }
\newlabel{fig:second_click}{{5}{13}{Proportion of second-click expansions on the same path as a function of the first revealed node's value. Human data (black) reveals a strong “best-first” tendency for high positive values, closely resembling the \textsc {Optimal} and \textsc {Best} curves}{figure.caption.32}{}}
\citation{Callaway2023rationaluse}
\citation{Callaway2023rationaluse}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces AIC Computation and Akaike Weights. \textsc  {Optimal} dominates in terms of both AIC and associated weight.}}{14}{table.caption.34}\protected@file@percent }
\newlabel{tab:AIC}{{2}{14}{AIC Computation and Akaike Weights. \textsc {Optimal} dominates in terms of both AIC and associated weight}{table.caption.34}{}}
\bibcite{Callaway2023rationaluse}{1}
\bibcite{griffiths2015rational}{2}
\bibcite{payne1993adaptive}{3}
\bibcite{sutton2018reinforcement}{4}
\@writefile{toc}{\contentsline {chapter}{Litteratur}{15}{chapter*.38}\protected@file@percent }
\memsetcounter{lastsheet}{15}
\memsetcounter{lastpage}{15}
\gdef \@abspage@last{15}
